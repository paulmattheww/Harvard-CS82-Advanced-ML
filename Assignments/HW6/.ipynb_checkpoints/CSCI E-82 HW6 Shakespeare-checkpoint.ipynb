{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from time import time\n",
    "import spacy\n",
    "from tld import get_tld\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alllines.txt', '.DS_Store', 'Shakespeare_data.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = list()\n",
    "with open('data/alllines.txt') as f:\n",
    "    lines.append(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"ACT I\"\\n',\n",
       " '\"SCENE I. London. The palace.\"\\n',\n",
       " '\"Enter KING HENRY, LORD JOHN OF LANCASTER, the EARL of WESTMORELAND, SIR WALTER BLUNT, and others\"\\n',\n",
       " '\"So shaken as we are, so wan with care,\"\\n',\n",
       " '\"Find we a time for frighted peace to pant,\"\\n',\n",
       " '\"And breathe short-winded accents of new broils\"\\n',\n",
       " '\"To be commenced in strands afar remote.\"\\n',\n",
       " '\"No more the thirsty entrance of this soil\"\\n',\n",
       " '\"Shall daub her lips with her own children\\'s blood,\"\\n',\n",
       " '\"Nor more shall trenching war channel her fields,\"\\n']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataline</th>\n",
       "      <th>Play</th>\n",
       "      <th>PlayerLinenumber</th>\n",
       "      <th>ActSceneLine</th>\n",
       "      <th>Player</th>\n",
       "      <th>PlayerLine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACT I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCENE I. London. The palace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>So shaken as we are, so wan with care,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Find we a time for frighted peace to pant,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataline      Play  PlayerLinenumber ActSceneLine         Player  \\\n",
       "0         1  Henry IV               NaN          NaN            NaN   \n",
       "1         2  Henry IV               NaN          NaN            NaN   \n",
       "2         3  Henry IV               NaN          NaN            NaN   \n",
       "3         4  Henry IV               1.0        1.1.1  KING HENRY IV   \n",
       "4         5  Henry IV               1.0        1.1.2  KING HENRY IV   \n",
       "\n",
       "                                          PlayerLine  \n",
       "0                                              ACT I  \n",
       "1                       SCENE I. London. The palace.  \n",
       "2  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n",
       "3             So shaken as we are, so wan with care,  \n",
       "4         Find we a time for frighted peace to pant,  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare = pd.read_csv('data/Shakespeare_data.csv')\n",
    "shakespeare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111396, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleaner(TransformerMixin):\n",
    "    \"\"\"Text cleaning to slot into sklearn interface\"\"\"\n",
    "\n",
    "    def __init__(self, remove_stopwords=True, remove_urls=True,\n",
    "                 remove_puncts=True, lemmatize=True, extra_punct='',\n",
    "                 custom_stopwords=[], custom_non_stopwords=[],\n",
    "                 verbose=True, parser='big'):\n",
    "        \"\"\"\n",
    "        INPUT: remove_stopwords - bool - remove is, there, he etc...\n",
    "               remove_urls - bool - 't www.monkey.com t' --> 't com t'\n",
    "               remove_punct - bool - all punct and digits gone\n",
    "               lemmatize - bool - whether to apply lemmtization\n",
    "               extra_punct - str - other characters to remove\n",
    "               custom_stopwords - list - add to standard stops\n",
    "               custom_non_stopwords - list - make sure are kept\n",
    "               verbose - bool - whether to print progress statements\n",
    "               parser - str - 'big' or small, one keeps more, and is slower\n",
    "        OUTPUT: self - **due to other method, not this one\n",
    "        \"\"\"\n",
    "        # Initialize passed Attributes to specify operations\n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.remove_urls = remove_urls\n",
    "        self.remove_puncts = remove_puncts\n",
    "        self.lemmatize = lemmatize\n",
    "\n",
    "        # Change how operations work\n",
    "        self.custom_stopwords = custom_stopwords\n",
    "        self.custom_non_stopwords = custom_non_stopwords\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # Set up punctation tranlation table\n",
    "        self.removals = string.punctuation + string.digits + extra_punct\n",
    "        self.trans_table = str.maketrans({key: None for key in self.removals})\n",
    "\n",
    "        #Load nlp model for parsing usage later\n",
    "        self.parser = spacy.load('en_core_web_sm', \n",
    "                                 disable=['parser','ner','textcat'])\n",
    "        #from spacy.lang.en import English\n",
    "        if parser == 'small':\n",
    "            self.parser = spacy.load('en')#English()\n",
    "\n",
    "        #Add custom stop words to nlp\n",
    "        for word in self.custom_stopwords:\n",
    "            self.parser.vocab[word].is_stop = True\n",
    "\n",
    "        #Set custom nlp words to be kept\n",
    "        for word in self.custom_non_stopwords:\n",
    "            self.parser.vocab[word].is_stop = False\n",
    "\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"take array of docs to clean array of docs\"\"\"\n",
    "        # Potential replace urls with tld ie www.monkey.com to com\n",
    "        if self.remove_urls:\n",
    "            start_time = time()\n",
    "            if self.verbose:\n",
    "                print(\"CHANGING URLS to TLDS...  \", end='')\n",
    "            X = [self.remove_url(doc) for doc in X]\n",
    "            if self.verbose:\n",
    "                print(f\"{time() - start_time:.0f} seconds\")\n",
    "\n",
    "        # Potentially remove punctuation\n",
    "        if self.remove_puncts:\n",
    "            start_time = time()\n",
    "            if self.verbose:\n",
    "                print(\"REMOVING PUNCTUATION AND DIGITS... \", end='')\n",
    "            X = [doc.lower().translate(self.trans_table) for doc in X]\n",
    "            if self.verbose:\n",
    "                print(f\"{time() - start_time:.0f} seconds\")\n",
    "\n",
    "        # Using Spacy to parse text\n",
    "        start_time = time()\n",
    "        if self.verbose:\n",
    "            print(\"PARSING TEXT WITH SPACY... \", end='')\n",
    "            \n",
    "        X = list(self.parser.pipe(X))\n",
    "        if self.verbose:\n",
    "            print(f\"{time() - start_time:.0f} seconds\")\n",
    "\n",
    "        # Potential stopword removal\n",
    "        if self.remove_stopwords:\n",
    "            start_time = time()\n",
    "            if self.verbose:\n",
    "                print(\"REMOVING STOP WORDS FROM DOCUMENTS... \", end='')\n",
    "            X = [[word for word in doc if not word.is_stop] for doc in X]\n",
    "            if self.verbose:\n",
    "                print(f\"{time() - start_time:.0f} seconds\")\n",
    "\n",
    "\n",
    "        # Potential Lemmatization\n",
    "        if self.lemmatize:\n",
    "            start_time = time()\n",
    "            if self.verbose:\n",
    "                print(\"LEMMATIZING WORDS... \", end='')\n",
    "            X = [[word.lemma_ for word in doc] for doc in X]\n",
    "            if self.verbose:\n",
    "                print(f\"{time() - start_time:.0f} seconds\")\n",
    "\n",
    "        # Put back to normal if no lemmatizing happened\n",
    "        if not self.lemmatize:\n",
    "            X = [[str(word).lower() for word in doc] for doc in X]\n",
    "\n",
    "        # Join Back up\n",
    "        return [' '.join(lst) for lst in X]\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"interface conforming, and allows use of fit_transform\"\"\"\n",
    "        return self\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_url(text):\n",
    "        \"\"\"\n",
    "        DESCR: given a url string find urls and replace with top level domain\n",
    "               a bit lazy in that if there are multiple all are replaced by first\n",
    "        INPUT: text - str - 'this is www.monky.com in text'\n",
    "        OUTPIT: str - 'this is <com> in text'\n",
    "        \"\"\"\n",
    "        # Define string to match urls\n",
    "        url_re = '((?:www|https?)(://)?[^\\s]+)'\n",
    "\n",
    "        # Find potential things to replace\n",
    "        matches = re.findall(url_re, text)\n",
    "        if matches == []:\n",
    "            return text\n",
    "\n",
    "        # Get tld of first match\n",
    "        match = matches[0][0]\n",
    "        try:\n",
    "            tld = get_tld(match, fail_silently=True, fix_protocol=True)\n",
    "        except ValueError:\n",
    "            tld = None\n",
    "\n",
    "        # failures return none so change to empty\n",
    "        if tld is None:\n",
    "            tld = \"\"\n",
    "\n",
    "        # make this obvsiouyly an odd tag\n",
    "        tld = f\"<{tld}>\"\n",
    "\n",
    "        # Make replacements and return\n",
    "        return re.sub(url_re, tld, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVING PUNCTUATION AND DIGITS... 0 seconds\n",
      "PARSING TEXT WITH SPACY... 33 seconds\n",
      "REMOVING STOP WORDS FROM DOCUMENTS... 1 seconds\n",
      "LEMMATIZING WORDS... 0 seconds\n"
     ]
    }
   ],
   "source": [
    "custom_stopwords = ['act', 'i', 'ii', 'iii', 'iv', 'v']\n",
    "lines = [str(l) for l in lines]\n",
    "#lines = [s.split('\\n') for s in lines]\n",
    "lines_clean = TextCleaner(custom_stopwords=custom_stopwords,\n",
    "                         remove_urls=False).transform(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scene', 'london', 'palacen', 'enter', 'king']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_clean[0].split()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_clean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

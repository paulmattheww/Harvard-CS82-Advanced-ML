{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSCI E-82  Homework 5 on CNNs\n",
    "\n",
    "### Due by 11/13/18 at 11:59pm EST to the Canvas dropbox\n",
    "\n",
    "## This is an individual homework so there should be no collaboration for this homework.\n",
    "\n",
    "\n",
    "### Under each problem, we have a place for you to write the answer, or write runnable code that will produce the answer.  Show your work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a busy time of year with homework and an exam coming up.  We are looking for a successful working result that builds upon the section code and enables you to gain some proficiency with this important and growing field of deep learning. \n",
    "\n",
    "Depending on your computer, some of the runs may still take a few minutes per epoch.  As a result, Problem 4 may take the better part of a day to run, so plan accordingly.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paul M. Washburn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ideas\n",
    "- trump tweets vs. stock and bond markets\n",
    "- topic extraction on trump tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "WikiArt is an amazing resource containing centuries of artwork.  Since such datasets are wonderful for deep learning, Kaggle has hosted a challenge to characterize the 'fingerprints' of various artists.  The Kaggle dataset contains metadata and also a set of images that have been resized so that the shorter dimension is 256 pixels.  To make this homework reasonably fast even for those without GPUs, we have further reduced the images to 64 x 64.  CNNs and neural networks in general prefer to have consistent sizes.  To achieve this, we cut the center 256 pixels from the longer dimension and then shrunk the images by a factor of 4. This isn't a perfect solution since it did cut off a few heads as you will see.\n",
    "\n",
    "The selected images are for portraits and landscapes.  No, we're not talking about the orientation but rather the content of the images. Thanks to help from Rashmi and Dave, we have a small enough data set that should give reasonable results in a timely manner even on just a CPU.\n",
    "\n",
    "The data were originally divided into a training and a test set.  We have further divided the training set into a train and validation set.  In this homework you will be using the training set and validation set to train and assess your deep learning models.  At the final step, you will see how well your final training worked on the test set.  In each of these directories, there is a truth.txt file that has the image name and whether it is a portrait or landscape scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow is installed and is version:  1.10.0\n",
      "Keras is installed and is version:  2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import glob\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from time import time\n",
    "\n",
    "if K.backend()=='tensorflow':\n",
    "    K.set_image_data_format('channels_last')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Tensorflow is installed and is version: \",  tf.__version__)\n",
    "print(\"Keras is installed and is version: \", tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainValTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir='./logs/{}'.format(time()), **kwargs):\n",
    "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
    "        training_log_dir = os.path.join(log_dir, 'training')\n",
    "        super(TrainValTensorBoard, self).__init__(training_log_dir, **kwargs)\n",
    "\n",
    "        # Log the validation metrics to a separate subdirectory\n",
    "        self.val_log_dir = os.path.join(log_dir, 'validation')\n",
    "\n",
    "    def set_model(self, model):\n",
    "        # Setup writer for validation metrics\n",
    "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
    "        super(TrainValTensorBoard, self).set_model(model)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Pop the validation logs and handle them separately with\n",
    "        # `self.val_writer`. Also rename the keys so that they can\n",
    "        # be plotted on the same figure with the training metrics\n",
    "        logs = logs or {}\n",
    "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
    "        for name, value in val_logs.items():\n",
    "            summary = tf.Summary()\n",
    "            summary_value = summary.value.add()\n",
    "            summary_value.simple_value = value.item()\n",
    "            summary_value.tag = name\n",
    "            self.val_writer.add_summary(summary, epoch)\n",
    "        self.val_writer.flush()\n",
    "\n",
    "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
    "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
    "        super(TrainValTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        super(TrainValTensorBoard, self).on_train_end(logs)\n",
    "        self.val_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/images64'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_table('data/images64/train/truth.txt', header=None)\n",
    "val_labels = pd.read_table('data/images64/validation/truth.txt', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Do Not Re-run Code Below, Only Run Once***\n",
    "```python\n",
    "os.mkdir(os.path.join(train_dir, 'landscape'))\n",
    "os.mkdir(os.path.join(train_dir, 'portrait'))\n",
    "os.mkdir(os.path.join(validation_dir, 'landscape'))\n",
    "os.mkdir(os.path.join(validation_dir, 'portrait'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# move training files\n",
    "for landscape_pic in train_labels.loc[train_labels[1]=='landscape', 0]:\n",
    "    current_home = os.path.join(train_dir, landscape_pic)\n",
    "    new_home = os.path.join(os.path.join(train_dir, 'landscape'), landscape_pic)\n",
    "    shutil.move(current_home, new_home)\n",
    "    \n",
    "for portrait_pic in train_labels.loc[train_labels[1]=='portrait', 0]:\n",
    "    current_home = os.path.join(train_dir, portrait_pic)\n",
    "    new_home = os.path.join(os.path.join(train_dir, 'portrait'), portrait_pic)\n",
    "    shutil.move(current_home, new_home)\n",
    "    \n",
    "# move validation files\n",
    "for landscape_pic in val_labels.loc[val_labels[1]=='landscape', 0]:\n",
    "    current_home = os.path.join(validation_dir, landscape_pic)\n",
    "    new_home = os.path.join(os.path.join(validation_dir, 'landscape'), landscape_pic)\n",
    "    shutil.move(current_home, new_home)\n",
    "    \n",
    "for portrait_pic in val_labels.loc[val_labels[1]=='portrait', 0]:\n",
    "    current_home = os.path.join(validation_dir, portrait_pic)\n",
    "    new_home = os.path.join(os.path.join(validation_dir, 'portrait'), portrait_pic)\n",
    "    shutil.move(current_home, new_home)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (5 points)\n",
    "\n",
    "Read in and display the first 5 portraits and the first 5 landscapes.  Note, if you are using the OpenCV tools, then the color may be distorted.  The cvtColor() method using cv2.COLOR_BGR2RGB may be useful.  However, it is likely easier to use the generator and plot_strip example from section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x360 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_files = glob.glob('data/images64/train/landscape/*.jpg')\n",
    "i = 0\n",
    "fig, axes = plt.subplots(1, 5, figsize=(17, 5))\n",
    "for f in train_files:\n",
    "    while i < 5:\n",
    "        img = Image.open(f)\n",
    "        axes[i].imshow(np.asarray(img))\n",
    "        img.close()\n",
    "    i += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (25 points)\n",
    "\n",
    "Construct a baseline CNN classifier using Keras for the training set and assess the validation set performance at each epoch. The goal is to correctly classify portraits from landscapes. Plot the resulting performance on the training and validation set as a function of epoch using the criteria over which you are optimizing.  You should run at least 20 epochs for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16315 images belonging to 2 classes.\n",
      "Found 8158 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# select batch_size\n",
    "batch_size = 256\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   #featurewise_center=True,\n",
    "                                   #featurewise_std_normalization=True,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=batch_size, # somewhat arbitrarily chosen\n",
    "        class_mode='binary')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                #featurewise_center=True,\n",
    "                                #featurewise_std_normalization=True,\n",
    "                                rotation_range=20,\n",
    "                                width_shift_range=0.2,\n",
    "                                height_shift_range=0.2,\n",
    "                                horizontal_flip=True)\n",
    "validation_generator = val_datagen.flow_from_directory(validation_dir,\n",
    "                                                        target_size=(64, 64),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 165s 2s/step - loss: 0.5147 - acc: 0.7456 - val_loss: 0.4054 - val_acc: 0.8146\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 162s 2s/step - loss: 0.3820 - acc: 0.8307 - val_loss: 0.3444 - val_acc: 0.8524\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 166s 2s/step - loss: 0.3449 - acc: 0.8540 - val_loss: 0.3155 - val_acc: 0.8702\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 166s 2s/step - loss: 0.3257 - acc: 0.8609 - val_loss: 0.2901 - val_acc: 0.8830\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 164s 2s/step - loss: 0.2989 - acc: 0.8796 - val_loss: 0.2790 - val_acc: 0.8945\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 167s 2s/step - loss: 0.2953 - acc: 0.8795 - val_loss: 0.2697 - val_acc: 0.8919\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 164s 2s/step - loss: 0.2827 - acc: 0.8876 - val_loss: 0.2678 - val_acc: 0.8960\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 166s 2s/step - loss: 0.2723 - acc: 0.8927 - val_loss: 0.2577 - val_acc: 0.8953\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 166s 2s/step - loss: 0.2700 - acc: 0.8937 - val_loss: 0.2594 - val_acc: 0.8943\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 166s 2s/step - loss: 0.2672 - acc: 0.8946 - val_loss: 0.2534 - val_acc: 0.9021\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 165s 2s/step - loss: 0.2648 - acc: 0.8946 - val_loss: 0.2382 - val_acc: 0.9061\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 161s 2s/step - loss: 0.2580 - acc: 0.8973 - val_loss: 0.2533 - val_acc: 0.9071\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 164s 2s/step - loss: 0.2543 - acc: 0.9001 - val_loss: 0.2484 - val_acc: 0.9015\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 163s 2s/step - loss: 0.2469 - acc: 0.9031 - val_loss: 0.2381 - val_acc: 0.9073\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 162s 2s/step - loss: 0.2447 - acc: 0.9033 - val_loss: 0.2262 - val_acc: 0.9138\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 167s 2s/step - loss: 0.2388 - acc: 0.9063 - val_loss: 0.2338 - val_acc: 0.9097\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 167s 2s/step - loss: 0.2365 - acc: 0.9090 - val_loss: 0.2237 - val_acc: 0.9130\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 169s 2s/step - loss: 0.2365 - acc: 0.9098 - val_loss: 0.2303 - val_acc: 0.9076\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 169s 2s/step - loss: 0.2404 - acc: 0.9052 - val_loss: 0.2341 - val_acc: 0.9058\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 168s 2s/step - loss: 0.2324 - acc: 0.9075 - val_loss: 0.2567 - val_acc: 0.8923\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "avg_pool1 (AveragePooling2D) (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 21, 21, 64)        51264     \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 21, 21, 32)        51232     \n",
      "_________________________________________________________________\n",
      "avg_pool2 (AveragePooling2D) (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              1606656   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 1,711,073\n",
      "Trainable params: 1,711,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "kernel_size = (3,3)\n",
    " \n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "model = Sequential(name='cnn')\n",
    "\n",
    "# first convolution\n",
    "model.add(Conv2D(32, kernel_size, activation='relu',\n",
    "                 input_shape=(64, 64, 3), \n",
    "                 name='conv1',\n",
    "                 padding='same'))\n",
    "model.add(AveragePooling2D(kernel_size, name='avg_pool1'))\n",
    "\n",
    "# second convolution\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', name = 'conv2', padding='same'))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', name = 'conv3', padding='same'))\n",
    "model.add(AveragePooling2D(kernel_size, name='avg_pool2'))\n",
    "\n",
    "# model.add(Conv2D(64, (5, 5), activation='relu', name = 'conv4'))\n",
    "# model.add(Conv2D(32, (5, 5), activation='relu', name = 'conv5'))\n",
    "# model.add(AveragePooling2D(kernel_size, name='max_pool3'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu', name='fc1')) #128\n",
    "model.add(Dense(1, activation='sigmoid', name='fc2'))\n",
    "\n",
    "sgd = SGD(lr = 0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              #optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              #optimizer=sgd,\n",
    "              optimizer=Adam(lr=1e-4, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# fit model\n",
    "history = model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=100,\n",
    "                            epochs=25,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=50,\n",
    "                            verbose=1, \n",
    "                            callbacks=[tensorboard, early_stopping])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/attempt_0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start tensorboard:\n",
    "\n",
    "```\n",
    "Pauls-MacBook-Pro:HW5 pmw$ tensorboard --logdir=logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (5 points)\n",
    "\n",
    "From the pattern of training and validation curves, describe what is good/bad and what you plan to do next to improve the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (45 points)\n",
    "\n",
    "This step is where we want you to do most of your personal learning.  Your goal is to improve the network using a combination of architecture choices, parameter tuning, and experimenting with different optimizers/dropout/regularization/etc. Treat each of these as separate optimization/exploration steps for now.  We would like to see 3 separate steps that cover different areas.  The format of the 3 steps should be as follows:\n",
    "  * State the hypothesis/strategy for how you will improve/explore a particular aspect.\n",
    "  * Describe what types of tests you are running and why (i.e. what range of parameters are you choosing and why)\n",
    "  * Include the code and results\n",
    "  * State your interpretation of the results\n",
    " \n",
    "We're not looking for research in deep learning, but we want you to gain some hands-on experience working with Keras and figuring out what works. A good example may be comparing strategies to overcome overfitting, or comparing a few different CNN architectures in terms of performance and speed, or comparing data augmentation types and results.  \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 1:  Adding another full convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 188s 2s/step - loss: 0.5693 - acc: 0.7221 - val_loss: 0.4646 - val_acc: 0.7817\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 179s 2s/step - loss: 0.4066 - acc: 0.8172 - val_loss: 0.3649 - val_acc: 0.8451\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 171s 2s/step - loss: 0.3770 - acc: 0.8340 - val_loss: 0.3373 - val_acc: 0.8585\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 169s 2s/step - loss: 0.3465 - acc: 0.8545 - val_loss: 0.3176 - val_acc: 0.8725\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 168s 2s/step - loss: 0.3179 - acc: 0.8711 - val_loss: 0.2994 - val_acc: 0.8816\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 172s 2s/step - loss: 0.3141 - acc: 0.8736 - val_loss: 0.3023 - val_acc: 0.8790\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 172s 2s/step - loss: 0.2985 - acc: 0.8796 - val_loss: 0.3089 - val_acc: 0.8697\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 171s 2s/step - loss: 0.3027 - acc: 0.8782 - val_loss: 0.2789 - val_acc: 0.8906\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 170s 2s/step - loss: 0.2907 - acc: 0.8836 - val_loss: 0.2637 - val_acc: 0.8953\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 169s 2s/step - loss: 0.2795 - acc: 0.8882 - val_loss: 0.2651 - val_acc: 0.8945\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 165s 2s/step - loss: 0.2718 - acc: 0.8911 - val_loss: 0.2668 - val_acc: 0.8928\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 171s 2s/step - loss: 0.2730 - acc: 0.8889 - val_loss: 0.2662 - val_acc: 0.8917\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "avg_pool1 (AveragePooling2D) (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 21, 21, 64)        51264     \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 21, 21, 32)        51232     \n",
      "_________________________________________________________________\n",
      "avg_pool2 (AveragePooling2D) (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 7, 7, 64)          51264     \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 7, 7, 32)          51232     \n",
      "_________________________________________________________________\n",
      "avg_pool3 (AveragePooling2D) (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              132096    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 339,009\n",
      "Trainable params: 339,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(777)\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "kernel_size = (3, 3)\n",
    " \n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "model = Sequential(name='cnn')\n",
    "\n",
    "# first convolution\n",
    "model.add(Conv2D(32, kernel_size, activation='relu',\n",
    "                 input_shape=(64, 64, 3), \n",
    "                 name='conv1',\n",
    "                 padding='same'))\n",
    "model.add(AveragePooling2D(kernel_size, name='avg_pool1'))\n",
    "\n",
    "# second convolution\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', name = 'conv2', padding='same'))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', name = 'conv3', padding='same'))\n",
    "model.add(AveragePooling2D(kernel_size, name='avg_pool2'))\n",
    "\n",
    "# third - new - convolution\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', name = 'conv4', padding='same'))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', name = 'conv5', padding='same'))\n",
    "model.add(AveragePooling2D(kernel_size, name='avg_pool3'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu', name='fc1'))\n",
    "model.add(Dense(1, activation='sigmoid', name='fc2'))\n",
    "\n",
    "sgd = SGD(lr = 0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              #optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              #optimizer=sgd,\n",
    "              optimizer=Adam(lr=1e-4, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# fit model\n",
    "history = model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=100,\n",
    "                            epochs=25,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=50,\n",
    "                            verbose=1, \n",
    "                            callbacks=[tensorboard, early_stopping])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/attempt_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 2:  Using `MaxPooling2D` will improve the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 171s 2s/step - loss: 0.5248 - acc: 0.7598 - val_loss: 0.3965 - val_acc: 0.8272\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 170s 2s/step - loss: 0.3770 - acc: 0.8372 - val_loss: 0.3397 - val_acc: 0.8555\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 170s 2s/step - loss: 0.3416 - acc: 0.8579 - val_loss: 0.3206 - val_acc: 0.8636\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 171s 2s/step - loss: 0.3199 - acc: 0.8678 - val_loss: 0.2974 - val_acc: 0.8756\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 170s 2s/step - loss: 0.3020 - acc: 0.8777 - val_loss: 0.2985 - val_acc: 0.8837\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 173s 2s/step - loss: 0.2825 - acc: 0.8875 - val_loss: 0.2700 - val_acc: 0.8921\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 167s 2s/step - loss: 0.2671 - acc: 0.8930 - val_loss: 0.2995 - val_acc: 0.8758\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 171s 2s/step - loss: 0.2656 - acc: 0.8918 - val_loss: 0.2731 - val_acc: 0.8892\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 171s 2s/step - loss: 0.2679 - acc: 0.8892 - val_loss: 0.2841 - val_acc: 0.8762\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 21, 21, 64)        51264     \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 21, 21, 32)        51232     \n",
      "_________________________________________________________________\n",
      "max_pool2 (MaxPooling2D)     (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 7, 7, 64)          51264     \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 7, 7, 32)          51232     \n",
      "_________________________________________________________________\n",
      "max_pool3 (AveragePooling2D) (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              132096    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 339,009\n",
      "Trainable params: 339,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "kernel_size = (3, 3)\n",
    " \n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "model = Sequential(name='cnn')\n",
    "\n",
    "# first convolution\n",
    "model.add(Conv2D(32, kernel_size, activation='relu',\n",
    "                 input_shape=(64, 64, 3), \n",
    "                 name='conv1',\n",
    "                 padding='same'))\n",
    "model.add(MaxPooling2D(kernel_size, name='max_pool1'))\n",
    "\n",
    "# second convolution\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', name = 'conv2', padding='same'))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', name = 'conv3', padding='same'))\n",
    "model.add(MaxPooling2D(kernel_size, name='max_pool2'))\n",
    "\n",
    "# third - new - convolution\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', name = 'conv4', padding='same'))\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', name = 'conv5', padding='same'))\n",
    "model.add(AveragePooling2D(kernel_size, name='max_pool3'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu', name='fc1'))\n",
    "model.add(Dense(1, activation='sigmoid', name='fc2'))\n",
    "\n",
    "sgd = SGD(lr = 0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              #optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              optimizer=Adam(lr=1e-4, decay=1e-6),#sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# fit model\n",
    "history = model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=100,\n",
    "                            epochs=25,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=50,\n",
    "                            verbose=1, \n",
    "                            callbacks=[tensorboard, early_stopping])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/attempt_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 3:  Regularizing L1 and L2 will improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - 636s 6s/step - loss: 0.4800 - acc: 0.7647 - val_loss: 0.3933 - val_acc: 0.8237\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 611s 6s/step - loss: 0.3732 - acc: 0.8342 - val_loss: 0.3409 - val_acc: 0.8530\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 606s 6s/step - loss: 0.3236 - acc: 0.8647 - val_loss: 0.2920 - val_acc: 0.8861\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 608s 6s/step - loss: 0.2955 - acc: 0.8786 - val_loss: 0.2627 - val_acc: 0.8957\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 610s 6s/step - loss: 0.2695 - acc: 0.8918 - val_loss: 0.2705 - val_acc: 0.8895\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 627s 6s/step - loss: 0.2552 - acc: 0.8968 - val_loss: 0.2780 - val_acc: 0.8887\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        4736      \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 32, 32, 64)        100416    \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 32, 32, 32)        100384    \n",
      "_________________________________________________________________\n",
      "max_pool2 (MaxPooling2D)     (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 16, 16, 64)        100416    \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 16, 16, 32)        100384    \n",
      "_________________________________________________________________\n",
      "max_pool3 (AveragePooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 2,505,537\n",
      "Trainable params: 2,505,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "kernel_size = (7, 7)\n",
    "pool_size = (2, 2)\n",
    " \n",
    "early_stopping = EarlyStopping(patience=2)\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "\n",
    "model = Sequential(name='cnn')\n",
    "\n",
    "# first convolution\n",
    "model.add(Conv2D(32, kernel_size, activation='relu',\n",
    "                 input_shape=(64, 64, 3), \n",
    "                 name='conv1',\n",
    "                 padding='same'))\n",
    "model.add(MaxPooling2D(pool_size, name='max_pool1'))\n",
    "\n",
    "# second convolution\n",
    "model.add(Conv2D(64, kernel_size, activation='relu', name = 'conv2', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size, activation='relu', name = 'conv3', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size, name='max_pool2'))\n",
    "\n",
    "# third - new - convolution\n",
    "model.add(Conv2D(64, kernel_size, activation='relu', name = 'conv4', padding='same'))\n",
    "model.add(Conv2D(32, kernel_size, activation='relu', name = 'conv5', padding='same'))\n",
    "model.add(AveragePooling2D(pool_size, name='max_pool3'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu', name='fc1'))\n",
    "model.add(Dense(1, activation='sigmoid', name='fc2'))\n",
    "\n",
    "sgd = SGD(lr = 0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              #optimizer=RMSprop(lr=1e-4),\n",
    "              optimizer=Adam(lr=1e-4, decay=1e-6),#sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# fit model\n",
    "history = model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=100,\n",
    "                            epochs=25,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=50,\n",
    "                            verbose=1, \n",
    "                            callbacks=[tensorboard, early_stopping])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/attempt_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 (10 points)\n",
    "\n",
    "Assess your best model on the test data.  Plot the corresponding ROC curve from the results (since we've provided the truth).  This was not directly covered in section, but will require a prediction using images in the same format as the training.  We suggest referring to the Keras API else use a Google to search to find how to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "avg_pool1 (AveragePooling2D) (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 21, 21, 64)        51264     \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 21, 21, 32)        51232     \n",
      "_________________________________________________________________\n",
      "avg_pool2 (AveragePooling2D) (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              1606656   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 1,711,073\n",
      "Trainable params: 1,711,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = load_weights('models/attempt_0.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.read_table('data/images64/test/truth.txt', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# run this only once\n",
    "os.mkdir(os.path.join(test_dir, 'landscape'))\n",
    "os.mkdir(os.path.join(test_dir, 'portrait'))\n",
    "\n",
    "# move test files\n",
    "for landscape_pic in test_labels.loc[test_labels[1]=='landscape', 0]:\n",
    "    current_home = os.path.join(test_dir, landscape_pic)\n",
    "    new_home = os.path.join(os.path.join(test_dir, 'landscape'), landscape_pic)\n",
    "    shutil.move(current_home, new_home)\n",
    "\n",
    "for portrait_pic in test_labels.loc[test_labels[1]=='portrait', 0]:\n",
    "    current_home = os.path.join(test_dir, portrait_pic)\n",
    "    new_home = os.path.join(os.path.join(test_dir, 'portrait'), portrait_pic)\n",
    "    shutil.move(current_home, new_home)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7379 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=1, # somewhat arbitrarily chosen\n",
    "        class_mode='binary')\n",
    "\n",
    "model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "\n",
    "skplt.metrics.plot_roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6 (5 points)\n",
    "\n",
    "Display the 5 images [worst] misclassified images for each class.  Worst is in brackets since certain architectures may only make a binary decision rather than a score.  In that case, plot 5 of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7 (2 points)\n",
    "How many hours did this homework take you? The answer to this question will not affect your grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last step (3 points)\n",
    "Save this notebook as LastnameFirstnameHW5.ipynb such as PriceDavid.ipynb. Create a pdf of this notebook named similarly. Submit both the python notebook and the pdf version to the Canvas dropbox. We require both versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
